{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bhuvanesh-Singla/Emojimation_Bhuvanesh_Version/blob/main/Copy_of_task1_v2_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HQY3_wwygVvP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from tensorflow import keras\n",
        "from keras import Sequential\n",
        "from keras import layers, models\n",
        "from keras.layers import Dense,Conv2D,MaxPooling2D,Flatten,BatchNormalization,Dropout\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import load_img\n",
        "from keras.layers import Conv2D, Dense, BatchNormalization, Activation, Dropout, MaxPooling2D, Flatten\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
        "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "import datetime\n",
        "from keras import regularizers\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure kaggle\n",
        "os.chdir('/root/')\n",
        "!mkdir -p .kaggle\n",
        "os.chdir('/root/.kaggle')\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1Y-o0TVcjehM8SZB3Nt8U3xkyeQu-Nse-' -O kaggle.json > /dev/null 2>&1\n",
        "!ls /root/.kaggle\n",
        "\n",
        "# Set permissions \n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "\n",
        "# Create data folder\n",
        "os.chdir('/content/')\n",
        "!rm -rf data\n",
        "!mkdir data\n",
        "os.chdir('data')\n",
        "!pwd\n",
        "\n",
        "# Download data\n",
        "!pip install -q kaggle\n",
        "!kaggle competitions download -c challenges-in-representation-learning-facial-expression-recognition-challenge\n",
        "!pwd\n",
        "!ls\n",
        "# Unzip data\n",
        "!unzip challenges-in-representation-learning-facial-expression-recognition-challenge.zip train.csv test.csv"
      ],
      "metadata": {
        "id": "A_Y6R5rqgbVE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "699cbf09-ca63-43a6-d4ec-c8c7d438da94"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kaggle.json\n",
            "/content/data\n",
            "Downloading challenges-in-representation-learning-facial-expression-recognition-challenge.zip to /content/data\n",
            " 92% 263M/285M [00:01<00:00, 201MB/s]\n",
            "100% 285M/285M [00:01<00:00, 155MB/s]\n",
            "/content/data\n",
            "challenges-in-representation-learning-facial-expression-recognition-challenge.zip\n",
            "Archive:  challenges-in-representation-learning-facial-expression-recognition-challenge.zip\n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('train.csv')\n",
        "print(data.head(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0Y0Cc-Mgd8w",
        "outputId": "54953c94-232a-4286-b7b6-48a3e3d293a6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   emotion                                             pixels\n",
            "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...\n",
            "1        0  151 150 147 155 148 133 111 140 170 174 182 15...\n",
            "2        2  231 212 156 164 174 138 161 173 182 200 106 38...\n",
            "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...\n",
            "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import numpy\n",
        "\n",
        "train_images = []\n",
        "train_labels = []\n",
        "categories_count = {}\n",
        "\n",
        "with open('train.csv') as train:\n",
        "\n",
        "    # Read train.csv file\n",
        "    csv_reader = csv.reader(train)\n",
        "    \n",
        "    next(csv_reader)  # Skip the header\n",
        "\n",
        "    for row in csv_reader:\n",
        "\n",
        "        # Append image\n",
        "        pixels_str = row[1]\n",
        "        pixels_list = [int(i) for i in pixels_str.split(' ')]\n",
        "        pixels_list = numpy.array(pixels_list, dtype='uint8')\n",
        "        image = pixels_list.reshape((48, 48))\n",
        "        train_images.append(image)\n",
        "\n",
        "        label_str = row[0]\n",
        "\n",
        "        # Calculate categories count\n",
        "        count = 0\n",
        "        if label_str in categories_count:\n",
        "            count = categories_count[label_str] + 1\n",
        "        categories_count[label_str] = count\n",
        "\n",
        "        # Append label\n",
        "        label = int(label_str)\n",
        "        train_labels.append(label)\n",
        "\n",
        "# Create numpy array of train images and labels\n",
        "x_train = numpy.array(train_images)\n",
        "y_train = numpy.array(train_labels)\n",
        "\n",
        "print('x_train shape: {0}'.format(x_train.shape))\n",
        "print('y_train shape: {0}'.format(y_train.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HViu1igcggw4",
        "outputId": "4c2dab06-4a0b-49b2-ee5d-b50c6a8c62ad"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (28709, 48, 48)\n",
            "y_train shape: (28709,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4FAAqy3wmkvb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categories = ('Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral')\n",
        "y_pos = numpy.arange(len(categories))\n",
        "\n",
        "counts = []\n",
        "for label in range(len(categories)):\n",
        "    label_str = str(label)\n",
        "    count = categories_count[label_str]\n",
        "    counts.append(count)\n",
        "\n",
        "# Draw histogram\n",
        "plt.bar(y_pos, counts, align='center')\n",
        "plt.xticks(y_pos, categories)\n",
        "plt.ylabel('Count')\n",
        "plt.title('FER2013 Dataset Categories')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YzII6OtRgjyK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "outputId": "5991e347-5f2f-44d6-ff07-4a8de81773ad"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.1, random_state=42)\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.1,random_state = 42)\n",
        "x_train, x_test , x_val= x_train / 255.0, x_test / 255.0, x_val / 255.0\n",
        "\n",
        "x_train = x_train.reshape(len(x_train), 48, 48, 1)\n",
        "x_test = x_test.reshape(len(x_test), 48, 48, 1)\n",
        "x_val = x_val.reshape(len(x_val),48,48,1)\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "metadata": {
        "id": "y9yoWQPQgl7C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7010aad-7bf6-4783-dc9a-4683bad9360f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(23254, 48, 48, 1)\n",
            "(2871, 48, 48, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "VECqUdjzEZpG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(height_shift_range = 0.3,\n",
        "                            width_shift_range = 0.2,\n",
        "                            rotation_range = 40,\n",
        "                            horizontal_flip = True,\n",
        "                             )"
      ],
      "metadata": {
        "id": "irGwhZM0skSc"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = models.Sequential([\n",
        "    layers.Conv2D(filters=64, kernel_size = (3,3),activation = 'relu', padding = 'same',input_shape =(48,48,1) ),\n",
        "    layers.Conv2D(filters=64, kernel_size = (3,3),activation = 'relu',padding = 'same' ),\n",
        "    layers.Conv2D(filters=64, kernel_size = (3,3),activation = 'relu',padding = 'same'),\n",
        "    layers.MaxPooling2D((2,2),strides = 2),\n",
        "    layers.Conv2D(filters=128, kernel_size = (3,3),activation = 'relu' , padding = 'same'),\n",
        "    layers.Conv2D(filters = 128, kernel_size = (3,3), activation = 'relu', padding = 'same'),\n",
        "    layers.Conv2D(filters = 128, kernel_size = (3,3), activation = 'relu', padding = 'same'),\n",
        "    layers.MaxPooling2D((2,2), strides = 2),\n",
        "    layers.Conv2D(filters = 256, kernel_size = (3,3), activation = 'relu', padding = 'same'),\n",
        "    layers.Conv2D(filters = 256, kernel_size = (3,3), activation = 'relu', padding = 'same'),\n",
        "    layers.Conv2D(filters = 256, kernel_size = (3,3), activation = 'relu', padding = 'same'),\n",
        "    layers.MaxPool2D((2,2), strides = 2),\n",
        "    layers.Conv2D(filters = 512, kernel_size = (3,3), activation = 'relu', padding = 'same'),\n",
        "    layers.Conv2D(filters = 512, kernel_size = (3,3), activation = 'relu', padding = 'same'),\n",
        "    layers.Conv2D(filters = 512, kernel_size = (3,3), activation = 'relu', padding = 'same'),\n",
        "    layers.MaxPool2D((2,2), strides = 2),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(4096, activation = 'relu'),\n",
        "    layers.Dropout(0.4),\n",
        "    layers.Dense(4096, activation = 'relu'),\n",
        "    layers.Dropout(0.4),\n",
        "    layers.Dense(2048, activation = 'relu'),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(7, activation = 'softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "HHKwXbZv_Btf"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.compile(\n",
        "    optimizer = Adam(learning_rate=0.00005),\n",
        "    loss = 'sparse_categorical_crossentropy',\n",
        "    metrics = ['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "LpSszEgRLeDJ"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callback = EarlyStopping(\n",
        "    monitor = 'loss',\n",
        "    min_delta = 0.0001,\n",
        "    patience = 5,\n",
        "    verbose = 1,\n",
        "    restore_best_weights=True\n",
        ")"
      ],
      "metadata": {
        "id": "Od-n-rRInj7b"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = datagen.flow(\n",
        "    x_train,\n",
        "    y = y_train,\n",
        "    batch_size = 32\n",
        ")"
      ],
      "metadata": {
        "id": "DCs8-0B_tr6j"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# val_generator = datagen.flow(\n",
        "#     x_val,\n",
        "#     y = y_val,\n",
        "#     batch_size = 32\n",
        "# )"
      ],
      "metadata": {
        "id": "CcioRvjd5Qp5"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_generator = datagen.flow(\n",
        "    x_test,\n",
        "    y = y_test,\n",
        "    batch_size = 32\n",
        ")"
      ],
      "metadata": {
        "id": "VL0G4-mM5Z3B"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.fit(train_generator, epochs = 1000, shuffle = True, validation_data=(x_val, y_val), callbacks=callback)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YH-6hTzMQQ-",
        "outputId": "5c1d91bc-468f-41bc-b31f-f5f496da2afb"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "727/727 [==============================] - 42s 50ms/step - loss: 1.8220 - accuracy: 0.2473 - val_loss: 1.8141 - val_accuracy: 0.2488\n",
            "Epoch 2/1000\n",
            "727/727 [==============================] - 34s 47ms/step - loss: 1.8131 - accuracy: 0.2506 - val_loss: 1.8104 - val_accuracy: 0.2488\n",
            "Epoch 3/1000\n",
            "727/727 [==============================] - 35s 49ms/step - loss: 1.8010 - accuracy: 0.2494 - val_loss: 1.7781 - val_accuracy: 0.2488\n",
            "Epoch 4/1000\n",
            "727/727 [==============================] - 34s 46ms/step - loss: 1.7914 - accuracy: 0.2510 - val_loss: 1.7636 - val_accuracy: 0.2697\n",
            "Epoch 5/1000\n",
            "727/727 [==============================] - 35s 48ms/step - loss: 1.7789 - accuracy: 0.2585 - val_loss: 1.7279 - val_accuracy: 0.2833\n",
            "Epoch 6/1000\n",
            "727/727 [==============================] - 34s 47ms/step - loss: 1.7538 - accuracy: 0.2704 - val_loss: 1.6945 - val_accuracy: 0.3088\n",
            "Epoch 7/1000\n",
            "727/727 [==============================] - 34s 47ms/step - loss: 1.7270 - accuracy: 0.2862 - val_loss: 1.6474 - val_accuracy: 0.3332\n",
            "Epoch 8/1000\n",
            "727/727 [==============================] - 35s 48ms/step - loss: 1.6938 - accuracy: 0.3068 - val_loss: 1.5839 - val_accuracy: 0.3653\n",
            "Epoch 9/1000\n",
            "727/727 [==============================] - 35s 48ms/step - loss: 1.6404 - accuracy: 0.3371 - val_loss: 1.5016 - val_accuracy: 0.4114\n",
            "Epoch 10/1000\n",
            "727/727 [==============================] - 35s 48ms/step - loss: 1.5574 - accuracy: 0.3818 - val_loss: 1.3911 - val_accuracy: 0.4687\n",
            "Epoch 11/1000\n",
            "727/727 [==============================] - 34s 47ms/step - loss: 1.4898 - accuracy: 0.4157 - val_loss: 1.4178 - val_accuracy: 0.4470\n",
            "Epoch 12/1000\n",
            "727/727 [==============================] - 35s 48ms/step - loss: 1.4323 - accuracy: 0.4396 - val_loss: 1.2833 - val_accuracy: 0.5132\n",
            "Epoch 13/1000\n",
            "727/727 [==============================] - 34s 47ms/step - loss: 1.3999 - accuracy: 0.4535 - val_loss: 1.2596 - val_accuracy: 0.5190\n",
            "Epoch 14/1000\n",
            "727/727 [==============================] - 34s 46ms/step - loss: 1.3535 - accuracy: 0.4760 - val_loss: 1.2510 - val_accuracy: 0.5120\n",
            "Epoch 15/1000\n",
            "727/727 [==============================] - 34s 47ms/step - loss: 1.3286 - accuracy: 0.4843 - val_loss: 1.2739 - val_accuracy: 0.5155\n",
            "Epoch 16/1000\n",
            "727/727 [==============================] - 34s 47ms/step - loss: 1.2955 - accuracy: 0.4960 - val_loss: 1.1900 - val_accuracy: 0.5395\n",
            "Epoch 17/1000\n",
            "727/727 [==============================] - 35s 48ms/step - loss: 1.2634 - accuracy: 0.5116 - val_loss: 1.2153 - val_accuracy: 0.5306\n",
            "Epoch 18/1000\n",
            "727/727 [==============================] - 34s 47ms/step - loss: 1.2393 - accuracy: 0.5242 - val_loss: 1.1736 - val_accuracy: 0.5522\n",
            "Epoch 19/1000\n",
            "727/727 [==============================] - 35s 48ms/step - loss: 1.2218 - accuracy: 0.5331 - val_loss: 1.1243 - val_accuracy: 0.5731\n",
            "Epoch 20/1000\n",
            "727/727 [==============================] - 34s 47ms/step - loss: 1.1946 - accuracy: 0.5415 - val_loss: 1.1322 - val_accuracy: 0.5631\n",
            "Epoch 21/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 1.1819 - accuracy: 0.5468 - val_loss: 1.1079 - val_accuracy: 0.5863\n",
            "Epoch 22/1000\n",
            "727/727 [==============================] - 34s 47ms/step - loss: 1.1656 - accuracy: 0.5536 - val_loss: 1.1042 - val_accuracy: 0.5817\n",
            "Epoch 23/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 1.1486 - accuracy: 0.5619 - val_loss: 1.0611 - val_accuracy: 0.5971\n",
            "Epoch 24/1000\n",
            "727/727 [==============================] - 34s 46ms/step - loss: 1.1311 - accuracy: 0.5729 - val_loss: 1.0921 - val_accuracy: 0.5937\n",
            "Epoch 25/1000\n",
            "727/727 [==============================] - 34s 47ms/step - loss: 1.1141 - accuracy: 0.5744 - val_loss: 1.0445 - val_accuracy: 0.6006\n",
            "Epoch 26/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 1.1061 - accuracy: 0.5790 - val_loss: 1.0508 - val_accuracy: 0.5898\n",
            "Epoch 27/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 1.0903 - accuracy: 0.5833 - val_loss: 1.0159 - val_accuracy: 0.6057\n",
            "Epoch 28/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 1.0750 - accuracy: 0.5911 - val_loss: 1.0094 - val_accuracy: 0.6138\n",
            "Epoch 29/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 1.0704 - accuracy: 0.5944 - val_loss: 1.0101 - val_accuracy: 0.6130\n",
            "Epoch 30/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 1.0552 - accuracy: 0.6024 - val_loss: 1.0071 - val_accuracy: 0.6076\n",
            "Epoch 31/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 1.0497 - accuracy: 0.6046 - val_loss: 1.0027 - val_accuracy: 0.6235\n",
            "Epoch 32/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 1.0284 - accuracy: 0.6092 - val_loss: 1.0119 - val_accuracy: 0.6134\n",
            "Epoch 33/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 1.0189 - accuracy: 0.6134 - val_loss: 1.0093 - val_accuracy: 0.6192\n",
            "Epoch 34/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 1.0182 - accuracy: 0.6174 - val_loss: 0.9579 - val_accuracy: 0.6424\n",
            "Epoch 35/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 1.0048 - accuracy: 0.6191 - val_loss: 0.9994 - val_accuracy: 0.6250\n",
            "Epoch 36/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 1.0007 - accuracy: 0.6193 - val_loss: 0.9554 - val_accuracy: 0.6366\n",
            "Epoch 37/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.9895 - accuracy: 0.6272 - val_loss: 0.9902 - val_accuracy: 0.6308\n",
            "Epoch 38/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.9814 - accuracy: 0.6278 - val_loss: 0.9900 - val_accuracy: 0.6293\n",
            "Epoch 39/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.9730 - accuracy: 0.6314 - val_loss: 0.9615 - val_accuracy: 0.6265\n",
            "Epoch 40/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.9589 - accuracy: 0.6380 - val_loss: 0.9616 - val_accuracy: 0.6374\n",
            "Epoch 41/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.9515 - accuracy: 0.6404 - val_loss: 0.9515 - val_accuracy: 0.6362\n",
            "Epoch 42/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.9461 - accuracy: 0.6427 - val_loss: 0.9441 - val_accuracy: 0.6463\n",
            "Epoch 43/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.9373 - accuracy: 0.6497 - val_loss: 0.9598 - val_accuracy: 0.6397\n",
            "Epoch 44/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.9294 - accuracy: 0.6466 - val_loss: 0.9634 - val_accuracy: 0.6362\n",
            "Epoch 45/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.9238 - accuracy: 0.6525 - val_loss: 0.9629 - val_accuracy: 0.6378\n",
            "Epoch 46/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.9154 - accuracy: 0.6523 - val_loss: 0.9418 - val_accuracy: 0.6447\n",
            "Epoch 47/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.9139 - accuracy: 0.6568 - val_loss: 0.9710 - val_accuracy: 0.6370\n",
            "Epoch 48/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.9028 - accuracy: 0.6606 - val_loss: 0.9694 - val_accuracy: 0.6393\n",
            "Epoch 49/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.8905 - accuracy: 0.6669 - val_loss: 0.9292 - val_accuracy: 0.6498\n",
            "Epoch 50/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.8879 - accuracy: 0.6645 - val_loss: 0.9885 - val_accuracy: 0.6424\n",
            "Epoch 51/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.8832 - accuracy: 0.6674 - val_loss: 0.9708 - val_accuracy: 0.6482\n",
            "Epoch 52/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.8724 - accuracy: 0.6738 - val_loss: 0.9621 - val_accuracy: 0.6443\n",
            "Epoch 53/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.8693 - accuracy: 0.6751 - val_loss: 0.9596 - val_accuracy: 0.6571\n",
            "Epoch 54/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.8640 - accuracy: 0.6758 - val_loss: 0.9297 - val_accuracy: 0.6714\n",
            "Epoch 55/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.8494 - accuracy: 0.6782 - val_loss: 0.9513 - val_accuracy: 0.6509\n",
            "Epoch 56/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.8481 - accuracy: 0.6791 - val_loss: 0.9425 - val_accuracy: 0.6513\n",
            "Epoch 57/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.8374 - accuracy: 0.6878 - val_loss: 0.9589 - val_accuracy: 0.6610\n",
            "Epoch 58/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.8348 - accuracy: 0.6868 - val_loss: 0.9709 - val_accuracy: 0.6544\n",
            "Epoch 59/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.8218 - accuracy: 0.6933 - val_loss: 0.9715 - val_accuracy: 0.6463\n",
            "Epoch 60/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.8165 - accuracy: 0.6933 - val_loss: 0.9672 - val_accuracy: 0.6486\n",
            "Epoch 61/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.8145 - accuracy: 0.6922 - val_loss: 1.0023 - val_accuracy: 0.6436\n",
            "Epoch 62/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.8066 - accuracy: 0.6991 - val_loss: 0.9969 - val_accuracy: 0.6440\n",
            "Epoch 63/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.7991 - accuracy: 0.6978 - val_loss: 0.9656 - val_accuracy: 0.6525\n",
            "Epoch 64/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.7864 - accuracy: 0.7041 - val_loss: 0.9717 - val_accuracy: 0.6552\n",
            "Epoch 65/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.7883 - accuracy: 0.7020 - val_loss: 0.9490 - val_accuracy: 0.6598\n",
            "Epoch 66/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.7747 - accuracy: 0.7068 - val_loss: 0.9467 - val_accuracy: 0.6583\n",
            "Epoch 67/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.7704 - accuracy: 0.7099 - val_loss: 1.0070 - val_accuracy: 0.6459\n",
            "Epoch 68/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.7606 - accuracy: 0.7131 - val_loss: 0.9498 - val_accuracy: 0.6548\n",
            "Epoch 69/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.7564 - accuracy: 0.7164 - val_loss: 0.9387 - val_accuracy: 0.6649\n",
            "Epoch 70/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.7466 - accuracy: 0.7194 - val_loss: 0.9867 - val_accuracy: 0.6563\n",
            "Epoch 71/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.7422 - accuracy: 0.7228 - val_loss: 1.0287 - val_accuracy: 0.6594\n",
            "Epoch 72/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.7305 - accuracy: 0.7257 - val_loss: 1.0478 - val_accuracy: 0.6347\n",
            "Epoch 73/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.7264 - accuracy: 0.7296 - val_loss: 0.9826 - val_accuracy: 0.6711\n",
            "Epoch 74/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.7205 - accuracy: 0.7287 - val_loss: 0.9911 - val_accuracy: 0.6703\n",
            "Epoch 75/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.7150 - accuracy: 0.7303 - val_loss: 1.0531 - val_accuracy: 0.6502\n",
            "Epoch 76/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.7041 - accuracy: 0.7374 - val_loss: 1.0561 - val_accuracy: 0.6432\n",
            "Epoch 77/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.7025 - accuracy: 0.7371 - val_loss: 1.0695 - val_accuracy: 0.6548\n",
            "Epoch 78/1000\n",
            "727/727 [==============================] - 34s 46ms/step - loss: 0.6905 - accuracy: 0.7387 - val_loss: 1.0236 - val_accuracy: 0.6610\n",
            "Epoch 79/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.6865 - accuracy: 0.7422 - val_loss: 0.9982 - val_accuracy: 0.6691\n",
            "Epoch 80/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.6755 - accuracy: 0.7448 - val_loss: 1.1151 - val_accuracy: 0.6548\n",
            "Epoch 81/1000\n",
            "727/727 [==============================] - 34s 46ms/step - loss: 0.6746 - accuracy: 0.7449 - val_loss: 1.0310 - val_accuracy: 0.6471\n",
            "Epoch 82/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.6635 - accuracy: 0.7498 - val_loss: 1.0391 - val_accuracy: 0.6517\n",
            "Epoch 83/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.6593 - accuracy: 0.7547 - val_loss: 1.1262 - val_accuracy: 0.6374\n",
            "Epoch 84/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.6507 - accuracy: 0.7573 - val_loss: 1.1644 - val_accuracy: 0.6343\n",
            "Epoch 85/1000\n",
            "727/727 [==============================] - 34s 46ms/step - loss: 0.6423 - accuracy: 0.7584 - val_loss: 1.0783 - val_accuracy: 0.6544\n",
            "Epoch 86/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.6435 - accuracy: 0.7570 - val_loss: 1.1699 - val_accuracy: 0.6478\n",
            "Epoch 87/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.6287 - accuracy: 0.7636 - val_loss: 1.0705 - val_accuracy: 0.6583\n",
            "Epoch 88/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.6257 - accuracy: 0.7663 - val_loss: 1.0638 - val_accuracy: 0.6629\n",
            "Epoch 89/1000\n",
            "727/727 [==============================] - 34s 46ms/step - loss: 0.6158 - accuracy: 0.7708 - val_loss: 1.1231 - val_accuracy: 0.6618\n",
            "Epoch 90/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.6047 - accuracy: 0.7731 - val_loss: 1.1796 - val_accuracy: 0.6536\n",
            "Epoch 91/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.6051 - accuracy: 0.7725 - val_loss: 1.1219 - val_accuracy: 0.6575\n",
            "Epoch 92/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.6016 - accuracy: 0.7732 - val_loss: 1.0731 - val_accuracy: 0.6668\n",
            "Epoch 93/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.5948 - accuracy: 0.7760 - val_loss: 1.0990 - val_accuracy: 0.6637\n",
            "Epoch 94/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.5855 - accuracy: 0.7788 - val_loss: 1.1251 - val_accuracy: 0.6521\n",
            "Epoch 95/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.5790 - accuracy: 0.7846 - val_loss: 1.1391 - val_accuracy: 0.6610\n",
            "Epoch 96/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.5725 - accuracy: 0.7860 - val_loss: 1.2005 - val_accuracy: 0.6521\n",
            "Epoch 97/1000\n",
            "727/727 [==============================] - 34s 46ms/step - loss: 0.5627 - accuracy: 0.7895 - val_loss: 1.1543 - val_accuracy: 0.6575\n",
            "Epoch 98/1000\n",
            "727/727 [==============================] - 34s 46ms/step - loss: 0.5621 - accuracy: 0.7898 - val_loss: 1.1648 - val_accuracy: 0.6494\n",
            "Epoch 99/1000\n",
            "727/727 [==============================] - 34s 46ms/step - loss: 0.5566 - accuracy: 0.7932 - val_loss: 1.1835 - val_accuracy: 0.6598\n",
            "Epoch 100/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.5438 - accuracy: 0.7951 - val_loss: 1.2176 - val_accuracy: 0.6610\n",
            "Epoch 101/1000\n",
            "727/727 [==============================] - 34s 46ms/step - loss: 0.5362 - accuracy: 0.8010 - val_loss: 1.2649 - val_accuracy: 0.6540\n",
            "Epoch 102/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.5316 - accuracy: 0.8038 - val_loss: 1.2208 - val_accuracy: 0.6451\n",
            "Epoch 103/1000\n",
            "727/727 [==============================] - 34s 46ms/step - loss: 0.5288 - accuracy: 0.8050 - val_loss: 1.2575 - val_accuracy: 0.6579\n",
            "Epoch 104/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.5137 - accuracy: 0.8075 - val_loss: 1.2944 - val_accuracy: 0.6594\n",
            "Epoch 105/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.5088 - accuracy: 0.8115 - val_loss: 1.3081 - val_accuracy: 0.6579\n",
            "Epoch 106/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.5096 - accuracy: 0.8104 - val_loss: 1.3220 - val_accuracy: 0.6680\n",
            "Epoch 107/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.4950 - accuracy: 0.8162 - val_loss: 1.3292 - val_accuracy: 0.6563\n",
            "Epoch 108/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.4985 - accuracy: 0.8120 - val_loss: 1.3352 - val_accuracy: 0.6745\n",
            "Epoch 109/1000\n",
            "727/727 [==============================] - 34s 46ms/step - loss: 0.4936 - accuracy: 0.8166 - val_loss: 1.4239 - val_accuracy: 0.6498\n",
            "Epoch 110/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.4797 - accuracy: 0.8223 - val_loss: 1.3727 - val_accuracy: 0.6533\n",
            "Epoch 111/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.4832 - accuracy: 0.8211 - val_loss: 1.3609 - val_accuracy: 0.6614\n",
            "Epoch 112/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.4771 - accuracy: 0.8204 - val_loss: 1.3791 - val_accuracy: 0.6571\n",
            "Epoch 113/1000\n",
            "727/727 [==============================] - 34s 46ms/step - loss: 0.4657 - accuracy: 0.8274 - val_loss: 1.2960 - val_accuracy: 0.6533\n",
            "Epoch 114/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.4684 - accuracy: 0.8264 - val_loss: 1.3298 - val_accuracy: 0.6529\n",
            "Epoch 115/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.4583 - accuracy: 0.8276 - val_loss: 1.5496 - val_accuracy: 0.6548\n",
            "Epoch 116/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.4516 - accuracy: 0.8298 - val_loss: 1.3894 - val_accuracy: 0.6637\n",
            "Epoch 117/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.4436 - accuracy: 0.8350 - val_loss: 1.4410 - val_accuracy: 0.6556\n",
            "Epoch 118/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.4415 - accuracy: 0.8337 - val_loss: 1.3098 - val_accuracy: 0.6641\n",
            "Epoch 119/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.4278 - accuracy: 0.8387 - val_loss: 1.3416 - val_accuracy: 0.6594\n",
            "Epoch 120/1000\n",
            "727/727 [==============================] - 34s 46ms/step - loss: 0.4218 - accuracy: 0.8427 - val_loss: 1.5209 - val_accuracy: 0.6618\n",
            "Epoch 121/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.4230 - accuracy: 0.8410 - val_loss: 1.5039 - val_accuracy: 0.6552\n",
            "Epoch 122/1000\n",
            "727/727 [==============================] - 34s 46ms/step - loss: 0.4029 - accuracy: 0.8524 - val_loss: 1.5537 - val_accuracy: 0.6536\n",
            "Epoch 123/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.4153 - accuracy: 0.8446 - val_loss: 1.5271 - val_accuracy: 0.6552\n",
            "Epoch 124/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.4113 - accuracy: 0.8457 - val_loss: 1.4840 - val_accuracy: 0.6591\n",
            "Epoch 125/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.4060 - accuracy: 0.8497 - val_loss: 1.6018 - val_accuracy: 0.6428\n",
            "Epoch 126/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.3939 - accuracy: 0.8559 - val_loss: 1.6060 - val_accuracy: 0.6482\n",
            "Epoch 127/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.3901 - accuracy: 0.8561 - val_loss: 1.5865 - val_accuracy: 0.6370\n",
            "Epoch 128/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.3899 - accuracy: 0.8528 - val_loss: 1.4595 - val_accuracy: 0.6420\n",
            "Epoch 129/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.3755 - accuracy: 0.8614 - val_loss: 1.5137 - val_accuracy: 0.6521\n",
            "Epoch 130/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.3773 - accuracy: 0.8611 - val_loss: 1.6454 - val_accuracy: 0.6676\n",
            "Epoch 131/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.3783 - accuracy: 0.8600 - val_loss: 1.5460 - val_accuracy: 0.6622\n",
            "Epoch 132/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.3693 - accuracy: 0.8632 - val_loss: 1.6225 - val_accuracy: 0.6544\n",
            "Epoch 133/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.3625 - accuracy: 0.8644 - val_loss: 1.6320 - val_accuracy: 0.6498\n",
            "Epoch 134/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.3582 - accuracy: 0.8667 - val_loss: 1.6728 - val_accuracy: 0.6405\n",
            "Epoch 135/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.3602 - accuracy: 0.8646 - val_loss: 1.5938 - val_accuracy: 0.6567\n",
            "Epoch 136/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.3432 - accuracy: 0.8733 - val_loss: 1.6551 - val_accuracy: 0.6505\n",
            "Epoch 137/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.3479 - accuracy: 0.8699 - val_loss: 1.5707 - val_accuracy: 0.6660\n",
            "Epoch 138/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.3478 - accuracy: 0.8715 - val_loss: 1.5087 - val_accuracy: 0.6571\n",
            "Epoch 139/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.3374 - accuracy: 0.8747 - val_loss: 1.6369 - val_accuracy: 0.6622\n",
            "Epoch 140/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.3318 - accuracy: 0.8753 - val_loss: 1.8081 - val_accuracy: 0.6660\n",
            "Epoch 141/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.3302 - accuracy: 0.8789 - val_loss: 1.6703 - val_accuracy: 0.6563\n",
            "Epoch 142/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.3214 - accuracy: 0.8809 - val_loss: 1.8176 - val_accuracy: 0.6563\n",
            "Epoch 143/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.3241 - accuracy: 0.8779 - val_loss: 1.5313 - val_accuracy: 0.6695\n",
            "Epoch 144/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.3152 - accuracy: 0.8816 - val_loss: 1.7649 - val_accuracy: 0.6459\n",
            "Epoch 145/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.3242 - accuracy: 0.8804 - val_loss: 1.6253 - val_accuracy: 0.6583\n",
            "Epoch 146/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.3063 - accuracy: 0.8875 - val_loss: 1.6478 - val_accuracy: 0.6637\n",
            "Epoch 147/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.3071 - accuracy: 0.8854 - val_loss: 1.7012 - val_accuracy: 0.6583\n",
            "Epoch 148/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.3102 - accuracy: 0.8875 - val_loss: 1.5588 - val_accuracy: 0.6625\n",
            "Epoch 149/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.3025 - accuracy: 0.8915 - val_loss: 1.6940 - val_accuracy: 0.6498\n",
            "Epoch 150/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.2908 - accuracy: 0.8923 - val_loss: 1.8411 - val_accuracy: 0.6552\n",
            "Epoch 151/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.2968 - accuracy: 0.8906 - val_loss: 1.8402 - val_accuracy: 0.6579\n",
            "Epoch 152/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.2854 - accuracy: 0.8948 - val_loss: 1.7514 - val_accuracy: 0.6552\n",
            "Epoch 153/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.2867 - accuracy: 0.8952 - val_loss: 1.8015 - val_accuracy: 0.6505\n",
            "Epoch 154/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.2838 - accuracy: 0.8946 - val_loss: 1.8562 - val_accuracy: 0.6602\n",
            "Epoch 155/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.2808 - accuracy: 0.8971 - val_loss: 1.7838 - val_accuracy: 0.6633\n",
            "Epoch 156/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.2741 - accuracy: 0.9007 - val_loss: 1.8217 - val_accuracy: 0.6556\n",
            "Epoch 157/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.2722 - accuracy: 0.8991 - val_loss: 1.7334 - val_accuracy: 0.6618\n",
            "Epoch 158/1000\n",
            "727/727 [==============================] - 34s 46ms/step - loss: 0.2721 - accuracy: 0.9003 - val_loss: 1.9076 - val_accuracy: 0.6525\n",
            "Epoch 159/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.2691 - accuracy: 0.9012 - val_loss: 1.8307 - val_accuracy: 0.6567\n",
            "Epoch 160/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.2674 - accuracy: 0.9017 - val_loss: 1.8746 - val_accuracy: 0.6525\n",
            "Epoch 161/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.2579 - accuracy: 0.9066 - val_loss: 1.9796 - val_accuracy: 0.6556\n",
            "Epoch 162/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.2584 - accuracy: 0.9046 - val_loss: 1.9275 - val_accuracy: 0.6552\n",
            "Epoch 163/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.2623 - accuracy: 0.9051 - val_loss: 1.9683 - val_accuracy: 0.6552\n",
            "Epoch 164/1000\n",
            "727/727 [==============================] - 34s 46ms/step - loss: 0.2549 - accuracy: 0.9072 - val_loss: 1.9324 - val_accuracy: 0.6540\n",
            "Epoch 165/1000\n",
            "727/727 [==============================] - 34s 46ms/step - loss: 0.2539 - accuracy: 0.9065 - val_loss: 2.0436 - val_accuracy: 0.6474\n",
            "Epoch 166/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.2554 - accuracy: 0.9090 - val_loss: 1.9915 - val_accuracy: 0.6552\n",
            "Epoch 167/1000\n",
            "727/727 [==============================] - 34s 46ms/step - loss: 0.2469 - accuracy: 0.9089 - val_loss: 2.0162 - val_accuracy: 0.6509\n",
            "Epoch 168/1000\n",
            "727/727 [==============================] - 34s 46ms/step - loss: 0.2434 - accuracy: 0.9112 - val_loss: 2.0750 - val_accuracy: 0.6602\n",
            "Epoch 169/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.2506 - accuracy: 0.9077 - val_loss: 1.8461 - val_accuracy: 0.6420\n",
            "Epoch 170/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.2396 - accuracy: 0.9139 - val_loss: 2.2007 - val_accuracy: 0.6560\n",
            "Epoch 171/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.2373 - accuracy: 0.9135 - val_loss: 1.9624 - val_accuracy: 0.6567\n",
            "Epoch 172/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.2380 - accuracy: 0.9136 - val_loss: 2.0256 - val_accuracy: 0.6614\n",
            "Epoch 173/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.2333 - accuracy: 0.9158 - val_loss: 1.9711 - val_accuracy: 0.6618\n",
            "Epoch 174/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.2338 - accuracy: 0.9138 - val_loss: 1.8731 - val_accuracy: 0.6529\n",
            "Epoch 175/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.2326 - accuracy: 0.9158 - val_loss: 1.9108 - val_accuracy: 0.6509\n",
            "Epoch 176/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.2300 - accuracy: 0.9158 - val_loss: 2.0240 - val_accuracy: 0.6560\n",
            "Epoch 177/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.2268 - accuracy: 0.9160 - val_loss: 2.0661 - val_accuracy: 0.6583\n",
            "Epoch 178/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.2218 - accuracy: 0.9192 - val_loss: 2.1715 - val_accuracy: 0.6598\n",
            "Epoch 179/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.2200 - accuracy: 0.9181 - val_loss: 2.0292 - val_accuracy: 0.6672\n",
            "Epoch 180/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.2214 - accuracy: 0.9216 - val_loss: 2.1076 - val_accuracy: 0.6618\n",
            "Epoch 181/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.2153 - accuracy: 0.9224 - val_loss: 2.0243 - val_accuracy: 0.6583\n",
            "Epoch 182/1000\n",
            "727/727 [==============================] - 34s 46ms/step - loss: 0.2131 - accuracy: 0.9235 - val_loss: 2.0691 - val_accuracy: 0.6560\n",
            "Epoch 183/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.2167 - accuracy: 0.9212 - val_loss: 2.0710 - val_accuracy: 0.6618\n",
            "Epoch 184/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.2094 - accuracy: 0.9221 - val_loss: 2.1870 - val_accuracy: 0.6413\n",
            "Epoch 185/1000\n",
            "727/727 [==============================] - 34s 46ms/step - loss: 0.2065 - accuracy: 0.9262 - val_loss: 2.1303 - val_accuracy: 0.6598\n",
            "Epoch 186/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.1990 - accuracy: 0.9275 - val_loss: 2.1722 - val_accuracy: 0.6610\n",
            "Epoch 187/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.2084 - accuracy: 0.9253 - val_loss: 2.2960 - val_accuracy: 0.6656\n",
            "Epoch 188/1000\n",
            "727/727 [==============================] - 34s 46ms/step - loss: 0.2088 - accuracy: 0.9235 - val_loss: 2.1995 - val_accuracy: 0.6536\n",
            "Epoch 189/1000\n",
            "727/727 [==============================] - 34s 46ms/step - loss: 0.1915 - accuracy: 0.9306 - val_loss: 2.4276 - val_accuracy: 0.6478\n",
            "Epoch 190/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.2043 - accuracy: 0.9273 - val_loss: 2.2669 - val_accuracy: 0.6602\n",
            "Epoch 191/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.1980 - accuracy: 0.9289 - val_loss: 2.3044 - val_accuracy: 0.6676\n",
            "Epoch 192/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.2020 - accuracy: 0.9267 - val_loss: 1.8687 - val_accuracy: 0.6389\n",
            "Epoch 193/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.1860 - accuracy: 0.9338 - val_loss: 2.1144 - val_accuracy: 0.6567\n",
            "Epoch 194/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.1916 - accuracy: 0.9297 - val_loss: 2.2961 - val_accuracy: 0.6591\n",
            "Epoch 195/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.1919 - accuracy: 0.9305 - val_loss: 2.3343 - val_accuracy: 0.6556\n",
            "Epoch 196/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.1897 - accuracy: 0.9323 - val_loss: 2.1663 - val_accuracy: 0.6602\n",
            "Epoch 197/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.1831 - accuracy: 0.9330 - val_loss: 2.1618 - val_accuracy: 0.6625\n",
            "Epoch 198/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.1877 - accuracy: 0.9312 - val_loss: 2.2159 - val_accuracy: 0.6637\n",
            "Epoch 199/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.1818 - accuracy: 0.9333 - val_loss: 2.3662 - val_accuracy: 0.6591\n",
            "Epoch 200/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.1825 - accuracy: 0.9354 - val_loss: 2.0586 - val_accuracy: 0.6594\n",
            "Epoch 201/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.1813 - accuracy: 0.9354 - val_loss: 2.1071 - val_accuracy: 0.6525\n",
            "Epoch 202/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.1762 - accuracy: 0.9373 - val_loss: 2.4309 - val_accuracy: 0.6567\n",
            "Epoch 203/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.1827 - accuracy: 0.9338 - val_loss: 2.1392 - val_accuracy: 0.6583\n",
            "Epoch 204/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.1771 - accuracy: 0.9369 - val_loss: 2.1247 - val_accuracy: 0.6571\n",
            "Epoch 205/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.1761 - accuracy: 0.9357 - val_loss: 2.1825 - val_accuracy: 0.6560\n",
            "Epoch 206/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.1726 - accuracy: 0.9381 - val_loss: 2.3026 - val_accuracy: 0.6540\n",
            "Epoch 207/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.1748 - accuracy: 0.9370 - val_loss: 2.2959 - val_accuracy: 0.6552\n",
            "Epoch 208/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.1726 - accuracy: 0.9372 - val_loss: 2.3264 - val_accuracy: 0.6614\n",
            "Epoch 209/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.1700 - accuracy: 0.9388 - val_loss: 2.0975 - val_accuracy: 0.6552\n",
            "Epoch 210/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.1784 - accuracy: 0.9342 - val_loss: 2.1404 - val_accuracy: 0.6556\n",
            "Epoch 211/1000\n",
            "727/727 [==============================] - 34s 46ms/step - loss: 0.1653 - accuracy: 0.9407 - val_loss: 2.4459 - val_accuracy: 0.6443\n",
            "Epoch 212/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.1675 - accuracy: 0.9403 - val_loss: 2.0975 - val_accuracy: 0.6548\n",
            "Epoch 213/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.1713 - accuracy: 0.9392 - val_loss: 2.1874 - val_accuracy: 0.6575\n",
            "Epoch 214/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.1618 - accuracy: 0.9414 - val_loss: 2.1660 - val_accuracy: 0.6598\n",
            "Epoch 215/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.1643 - accuracy: 0.9407 - val_loss: 2.3937 - val_accuracy: 0.6591\n",
            "Epoch 216/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.1687 - accuracy: 0.9398 - val_loss: 2.3132 - val_accuracy: 0.6517\n",
            "Epoch 217/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.1639 - accuracy: 0.9399 - val_loss: 2.2923 - val_accuracy: 0.6548\n",
            "Epoch 218/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.1614 - accuracy: 0.9424 - val_loss: 2.1749 - val_accuracy: 0.6633\n",
            "Epoch 219/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.1598 - accuracy: 0.9436 - val_loss: 2.3636 - val_accuracy: 0.6579\n",
            "Epoch 220/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.1621 - accuracy: 0.9422 - val_loss: 2.2120 - val_accuracy: 0.6548\n",
            "Epoch 221/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.1599 - accuracy: 0.9438 - val_loss: 2.3216 - val_accuracy: 0.6552\n",
            "Epoch 222/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.1564 - accuracy: 0.9438 - val_loss: 2.2251 - val_accuracy: 0.6587\n",
            "Epoch 223/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.1579 - accuracy: 0.9425 - val_loss: 2.4743 - val_accuracy: 0.6548\n",
            "Epoch 224/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.1558 - accuracy: 0.9455 - val_loss: 2.5452 - val_accuracy: 0.6471\n",
            "Epoch 225/1000\n",
            "727/727 [==============================] - 34s 46ms/step - loss: 0.1472 - accuracy: 0.9466 - val_loss: 2.5001 - val_accuracy: 0.6478\n",
            "Epoch 226/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.1565 - accuracy: 0.9435 - val_loss: 2.2041 - val_accuracy: 0.6598\n",
            "Epoch 227/1000\n",
            "727/727 [==============================] - 33s 45ms/step - loss: 0.1523 - accuracy: 0.9457 - val_loss: 2.4840 - val_accuracy: 0.6474\n",
            "Epoch 228/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.1533 - accuracy: 0.9442 - val_loss: 2.1582 - val_accuracy: 0.6579\n",
            "Epoch 229/1000\n",
            "727/727 [==============================] - 33s 46ms/step - loss: 0.1555 - accuracy: 0.9447 - val_loss: 2.5912 - val_accuracy: 0.6567\n",
            "Epoch 230/1000\n",
            "726/727 [============================>.] - ETA: 0s - loss: 0.1491 - accuracy: 0.9472Restoring model weights from the end of the best epoch: 225.\n",
            "727/727 [==============================] - 34s 46ms/step - loss: 0.1492 - accuracy: 0.9471 - val_loss: 2.2589 - val_accuracy: 0.6517\n",
            "Epoch 230: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fed10f60ac0>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = cnn.evaluate(x_test, y_test)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkZftcItXEQA",
        "outputId": "cedaf802-809d-4ace-f1b4-ba6a26417bfa"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90/90 [==============================] - 2s 23ms/step - loss: 2.4930 - accuracy: 0.6573\n",
            "Test accuracy: 0.6572622656822205\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "3"
      ],
      "metadata": {
        "id": "hhU3uMjYZ9sO"
      },
      "execution_count": 27,
      "outputs": []
    }
  ]
}